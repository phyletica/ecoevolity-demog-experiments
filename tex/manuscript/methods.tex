% During an ``event'' at time \etime, one or more demographic changes and/or
% divergences can occur.
% We estimate the number and timing of events and the assignment of comparisons
% to those events under a Dirichlet-process \citep{Ferguson1973,Antoniak1974}
% prior model.
% The \emph{a priori} tendency for comparisons to share events is controlled by
% the concentration parameter (\concentration) of the Dirichlet process.
% We use Markov chain Monte Carlo (MCMC) algorithms
% \citep{Metropolis1953,Hastings1970,Neal2000}
% to sample from the joint posterior of the model.
% See Appendix~\ref{appendix:model} for a full description of the model, and
% Table~\ref{table:notation} for a key to the notation we use throughout this
% paper.

\subsection{Analyses of simulated data}

\subsubsection{Assessing ability to estimate timing and sharing of demographic changes}

We used the \simcoevolity and \ecoevolity tools within the \ecoevolity software
package
\citep{Oaks2018ecoevolity}
to simulate and analyze \datasets, respectively, under a variety of conditions.
Each simulated \dataset comprised 500,000 unlinked biallelic characters from 10
diploid individuals (20 genomes) sampled per population from three demographic
comparisons.
We specified the concentration parameter of the Dirichlet process so that the
mean number of demographic change events was two ($\concentration = 1.414216$).
We assumed the mutation rates of all three populations were equal and 1, such
that time and effective population sizes were scaled by the mutation rate.
When analyzing each simulated \dataset, we ran four MCMC chains for 75,000
generations with a sample taken every 50 generations.
From preliminary analyses, we calculated the potential scale reduction factor
\citep[PSRF; the square root of Equation 1.1 in][]{Brooks1998} and effective
sample size \citep[ESS;][]{Gong2014} from the four chains for all continuous
parameters and the log likelihood using the \texttt{pyco-sumchains} tool of
\pycoevolity (Version 0.1.2 Commit 89d90a1).
Based on these metrics of MCMC convergence and mixing, we conservatively chose
to summarize the last 1000 samples from each chain for a total of 4000 samples
of parameter values to approximate the posterior distribution for every
simulated data set.
When plotting results, we highlight any simulation replicates that have a
$\textrm{PSRF} > 1.2$.

%% Initial simulation conditions removed

% \paragraph{Simulation conditions chosen to improve performance}
Initially, we simulated data under a variety of settings we thought covered
regions of parameter space that are both conducive and challenging for
estimating the timing and sharing of demographic changes.
However, estimates were quite poor across all our initial simulation conditions
(see Supporting Information).
In an effort to find conditions under which the timing and sharing of
demographic changes could be better estimated, and avoid combinations of
parameter values that caused parameter identifiability problems in our initial
analyses,
we explored simulations under gamma distributions on times and population sizes
offset from zero, and with recent demographic event times,
(\valsimcondition{1}--\valsimcondition{5}, Table~\ref{table:simconditions}).
When we specify an ``offset,'' we are right-shifting the entire gamma distribution to
have a lower limit of the offset value, rather than zero.
% Event time ~ gamma(shape=4.0, scale=0.000475, offset=0.0001); mean 0.002
% relative root size ~ gamma(shape=5.0, scale = 0.04, offset = 0.05); mean 0.25
% relative root size ~ gamma(shape=5.0, scale = 0.09, offset = 0.05); mean 0.5
% relative root size ~ gamma(shape=5.0, scale = 0.79, offset = 0.05); mean 4
% relative root size ~ gamma(shape=5.0, scale = 0.19, offset = 0.05); mean 1
% relative root size ~ gamma(shape=50.0, scale = 0.02, offset = 0.0); mean 1

\ifembed{
\input{table-sim-conditions.tex}
}{}

For the mutation-scaled effective size of the descendant
population
($\epopsize[\descendantpopindex{}]\murate$),
we used an offset gamma distribution with a shape of 4, offset of 0.0001, and
mean of 0.0021 after accounting for the offset
(Table~\ref{table:simconditions}).
The mean of this distribution corresponds to an average number of differences
per character between individuals in the population (i.e., nucleotide
diversity) of 0.0084, which is comparable to estimates from genomic data of
populations of
zooplankton \citep{Choquet2019},
stickleback fish \citep{Hohenlohe2010},
and humans \citep{Auton2015}.
For the distribution of event times, we used a gamma distribution with a shape
of 4, offset of 0.0001, and a mean of 0.002 (after accounting for the offset;
Table~\ref{table:simconditions}).
Taken together, this creates a distribution of event times in units of
$4N_e$ generations with a mean of approximately 0.3.
We chose these distributions to try and balance the number of gene lineages
that coalesce after and before the population-size change for the average gene
tree.
We used the offset values to avoid very small descendant population sizes and
very recent times of population-size change, because in our preliminary
analyses, both of these conditions caused the timing of events to be
essentially nonidentifiable (see Supporting Information).

We chose five different distributions on the
relative effective size of the ancestral population
(\rootrelativepopsize;
see Table~\ref{table:simconditions} and left column of
\figs \ref{fig:valsimsetimesopt} and \ref{fig:valsimsmodelopt}),
which ranged from having a mean 4-fold population-size increase (\vsimfourinc)
and decrease (\vsimfourdec),
and a ``worst-case'' scenario
where there was essentially no population-size change in the
history of the populations (\vsimnochange).
% \begin{enumerate}[label=B.\arabic*]
%     \item \dogamma{5}{0.25}{0.05} (4-fold population increase) \label{sims:optimalFourFoldIncrease}
%     \item \dogamma{5}{0.5}{0.05} (2-fold population increase)  \label{sims:optimalTwoFoldIncrease}
%     \item \dogamma{5}{4}{0.05} (4-fold population decrease)    \label{sims:optimalFourFoldDecrease}
%     \item \dogamma{5}{1}{0.05} (no change on average, but a fair amount of variation) \label{sims:optimalCenter}
%     \item \dogamma{50}{1}{0} (no change on average, little variance) \label{sims:optimalCenterNarrow}
% \end{enumerate}
We generated 500 \datasets under each of these five conditions
(\valsimcondition{1}--\valsimcondition{5}, Table~\ref{table:simconditions}),
and analyzed all of them using priors that matched the generating
distributions.

To assess the affect of varying the number of demographic comparisons
we repeated the simulations and analyses under Condition~\vsimfourinc,
but with six demographic comparisons rather than three.
Likewise, to assess the affect of varying the number of individuals sampled
from each population, we repeated the simulations and analyses under
Condition~\vsimfourinc, but with 20 individuals sampled per population (40
sampled genomes) rather than 10 (20 genomes).


\subsubsection{Simulations to assess sensitivity to prior assumptions}

% Sim disributions:
% Event time ~ gamma(shape=4.0, scale=0.000475, offset=0.0001); mean 0.002
% relative root size ~ gamma(shape=5.0, scale = 0.04, offset = 0.05); mean 0.25
% descendant size ~ gamma(4.0, scale=0.0005, offset = 0.0001); mean 0.0021
% Priors:
% Event time ~ exponential(mean = 0.005)
% relative root size ~ Exponential(mean = 2.0)
% descendant size ~ gamma(2.0, scale 0.001); mean 0.002

In the validation analyses above, the prior distributions used in analyses
matched the true underlying distributions under which the data were generated.
While this is an important first step when validating a Bayesian method
and exploring its behavior under ideal conditions,
this is unrealistic for real-world applications
where our priors are always wrong and usually much more diffuse to express
ignorance about the timing of past evolutionary events and historical effective
population sizes.
Also, having the priors match the true distributions effectively
limits how extreme the simulating distributions can be.
For example, the simulation condition \vsimfourinc above, where the
distribution on the effective size of the ancestral population is sharply
peaked at 0.25 (i.e., a four-fold population expansion), becomes a very
informative prior distribution when analyzing the simulated data;
more informative than is practical for most empirical applications of the
method.
Accordingly, we also analyzed data under conditions where the prior
distributions are more diffuse than those under which the data were simulated.
This allows us to
(1) see how sensitive the method is to prior misspecification,
(2) determine to what degree the results under conditions like \vsimfourinc are
influenced by the sharply informative prior on the ancestral population size,
and
(3) explore more extreme simulation conditions of population expansions and
contractions (conditions that would be unrealistic for a prior distribution).

We used the same distribution on event times and descendant effective
population sizes as for Conditions \valsimcondition{1}--\valsimcondition{5}
above.
For the relative effective size of the ancestral population
(\rootrelativepopsize), we chose four distributions under which to simulate
data
(\missimcondition{1}--\missimcondition{4}, Table~\ref{table:simconditions})
that are sharply peaked on four-fold and ten-fold population
expansions and contractions.
We simulated 500 \datasets under each of these four conditions and then
analyzed them under diffuse prior distributions.
We chose the prior distributions to reflect realistic amounts of prior
uncertainty about the timing of demographic changes and past and present
effective population sizes when analyzing empirical data.
Note, Conditions \vsimfourinc and \msimfourinc share the same simulating
distributions, which allows us to compare results to determine how much the
strongly informative prior on the ancestral population size affected inference.

For comparison, we also repeated simulations and analyses under Conditions
\vsimfourinc and \msimfourinc, except with three \emph{divergence} comparisons.
For these divergence comparisons, we simulated 10 sampled genomes per
population to match the same total number of samples per comparison (20) as the
demographic simulations.


\subsubsection{Simulating a mix of divergence and demographic comparisons}

To explore how well our method can infer a mix of shared demographic changes
and divergence times, we simulated 500 \datasets comprised of 6 comparisons:
3 demographic comparisons and
3 divergence comparisons.
To ensure the same amount of data across comparisons, we simulated
20 sampled genomes (10 diploid individuals) from each comparison
(i.e., 10 genomes from each population of each divergence comparison).
We used the same simulation conditions described above for
\vsimtwoinc,
and specified these same distributions as priors when analyzing all of the
simulated \datasets.


\subsubsection{Simulating linked sites}
Our model assumes each character is effectively unlinked.
To assess the effect of violating this assumption, we simulated \datasets
comprising 5000 100-base-pair loci (500,000 total characters).
All 100 characters from each locus evolved along the same gene tree that is
independent (conditional on the population history) from all other loci.
The distributions on parameters were the same
as the conditions described for \vsimfourinc above.
These same distributions were used as priors when analyzing the simulated
\datasets.

% \subsubsection{Data-acquisition bias?}


\subsection{Empirical application to stickleback data}


\subsubsection{Assembly of loci}
We assembled the publicly available RADseq data collected by
\citet{Hohenlohe2010}
from five populations of threespine sticklebacks (\spp{Gasterosteus aculeatus})
from south-central Alaska.
After downloading the reads mapped to the stickleback genome by
\citet{Hohenlohe2010}
from Dryad
(doi:10.5061/dryad.b6vh6),
we assembled reference guided alignments of loci in Stacks v1.48
\citet{Catchen2013} with a minimum read depth of 3 identical reads per locus
within each individual and the bounded single-nucleotide polymorphism (SNP)
model with error bounds between
0.001 and 0.01.
To maximize the number of loci and minimize paralogy, we assembled each
population separately;
because \ecoevolity models each population separately
(\fig{}~\ref{fig:modelCartoon}),
the characters do not need to be orthologous across populations, only within
them.

\subsubsection{Inferring shared demographic changes with \ecoevolity}

When analyzing the stickleback data with \ecoevolity, we used a value for the
concentration parameter of the Dirichlet process that corresponds to a mean
number of three events
($\concentration = 2.22543$).
We used the following prior distributions on the timing of events and effective
sizes of populations:
$\etime \sim \dexponential{0.001}$,
$\rootrelativepopsize \sim \dexponential{1}$,
and
$\epopsize[\descendantpopindex{}] \sim \dgamma{2}{0.002}$.
% \begin{itemize}
%     \item $\etime \sim \dexponential{0.001}$
%     \item $\rootrelativepopsize \sim \dexponential{1}$
%     \item $\epopsize[\descendantpopindex{}] \sim \dgamma{2}{0.002}$
% \end{itemize}
To assess the sensitivity of the results to these prior assumptions,
we also analyzed the data under two additional priors on
the concentration parameter, event times, and relative
effective population size of the ancestral population:
\begin{itemize}
    \item $\concentration = 13$ (half of prior probability on 5 events)
    \item $\concentration = 0.3725$ (half of prior probability on 1 event)
    \item $\etime \sim \dexponential{0.0005}$
    \item $\etime \sim \dexponential{0.01}$
    \item $\rootrelativepopsize \sim \dexponential{0.5}$
    \item $\rootrelativepopsize \sim \dexponential{0.1}$
\end{itemize}

For each prior setting, we ran 10 MCMC chains for 150,000 generations, sampling
every 100 generations; we did this using all the sites in the assembled
stickleback loci and only variable sites (i.e., SNPs).
To assess convergence and mixing of the chains, we calculated the PSRF
\citep{Brooks1998}
and ESS \citep{Gong2014} of all continuous parameters and the log likelihood
using the \texttt{pyco-sumchains} tool of \pycoevolity (Version 0.1.2 Commit
89d90a1).
We also visually inspected the sampled log likelihood and parameters values
over generations with the program Tracer \citep[Version 1.6;][]{Tracer16}.
The MCMC chains for all analyses converged almost immediately; we
conservatively removed the first 101 samples from each chain, resulting in
14,000 samples from the posterior (1400 samples from 10 chains) for each
analysis.
